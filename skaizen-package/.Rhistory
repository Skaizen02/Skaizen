color = palette_light()[[2]],
data = corrr_analysis %>% filter(views > 0)) +
geom_point(color = palette_light()[[2]],
data = corrr_analysis %>% filter(views > 0)) +
# Negative Correlations - less views
geom_segment(aes(xend = 0, yend = feature),
color = palette_light()[[1]],
data = corrr_analysis %>% filter(views < 0)) +
geom_point(color = palette_light()[[1]],
data = corrr_analysis %>% filter(views < 0)) +
# Vertical lines
geom_vline(xintercept = 0, color = palette_light()[[5]], size = 1, linetype = 2) +
geom_vline(xintercept = -0.25, color = palette_light()[[5]], size = 1, linetype = 2) +
geom_vline(xintercept = 0.25, color = palette_light()[[5]], size = 1, linetype = 2) +
# Aesthetics
theme_tq() +
labs(title = "Keywords/Views Correlation Analysis",
subtitle = "Positive Correlations (more views), Negative Correlations (less views)",
y = "Feature Importance") +
theme(text = element_text(size=8))
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/WebCrawler.R')
write.csv(df, "/Final/data.csv")
write.csv(df, "data.csv")
write.csv(df, "Final/data.csv")
write.csv(df, "Skaizen/Final/data.csv")
selectors = list()
selectors[["titre"]] = "#title"
selectors
selectors[["tags"]] = ".tag"
selectors
selectors$tags
seletors[["tags"]]
selectors[["tags"]]
libary(roxygen)
library(devtools)
devtools!!install_github("klutometis/roxygen")
devtools::install_github("klutometis/roxygen")
install.packages("roxygen2")
setwd("C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package")
#' Crawler Function
#'
#' This function finds links by going from page to page, starting at a given page.
#' @param iterations
library(rvest)
library(beepr)
library(progress)
crawler <- function(iterations, url, path, step = 10, n = 100, beep = F) {
links <- list()
link <- url
pb <- progress_bar$new(total = n, format = "[:bar] :percent : :elapsed/:eta")
for (i in 1:n) {
if (!pb$finished) pb$tick()
if (!(link %in% scannedLinks)) {
pageLinks <- extractor(link)
pageLinks <- pageLinks[which(startsWith(pageLinks, path))]
pageLinks <- lapply(pageLinks, function(x) {
paste(url, x, sep = "")
})
links <- c(links, pageLinks)
}
link <- links[[i]]
}
links <- unlist(lapply(links, function(x) as.character(x)))
if(beep) beep()
links
}
crawler("https://www.finextra.com", "/newsarticle")
crawler("https://www.finextra.com", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
crawler("https://www.finextra.com", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
links <- crawler("https://www.finextra.com", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/extractor.R')
links <- crawler("https://www.finextra.com", "/newsarticle")
View(links)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
links <- crawler("https://www.finextra.com", "/newsarticle")
links <- crawler("https://www.finextra.com", "/newsarticle", n = 200)
links <- crawler("https://www.finextra.com", "/newsarticle", n = 600)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/extractor.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
df <- parser(links = )
df <- parser(links)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
df <- parser(links)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
hmtl_time <- as.numeric(Sys.time()*1000, digits=15)
html_time
hmtl_time <- as.numeric(Sys.time()*1000)
hmtl_time <- as.numeric(Sys.time())*1000
html_tioe
html_time
html_time <- as.numeric(Sys.time())*1000
html_time
print(html_time, digits = 15)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
message("Read_html : ")
print(startTime - as.numeric(Sys.time()), digits = 15)
startTime <- as.integer(Sys.time())
message("Read_html : ")
print(startTime - as.numeric(Sys.time()), digits = 15)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
message("Read_html : ")
print(as.numeric(Sys.time()) - startTime, digits = 15)
startTime <- as.integer(Sys.time())
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
startTime <- as.integer(Sys.time())
message("Read_html : ")
print((as.numeric(Sys.time()) - startTime)*1000, digits = 15)
print((as.numeric(Sys.time()) - startTime)*1000)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
df <- parser(links, n = 10)
df <- parser(links, limit = 10)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
df <- parser(links, limit = 1)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
html_time <- Sys.time()
message(paste("HTML : ", print(html_time - startTime)*1000))
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
html_time <- as.numeric(Sys.time())
message(paste("HTML : ", print((html_time - startTime)*1000)))
startTime <- as.integer(Sys.time())
message(paste("HTML : ", print((html_time - startTime)*1000)))
html_time <- as.numeric(Sys.time())
message(paste("HTML : ", print((html_time - startTime)*1000)))
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
message(paste("HTML : ", print((html_time - startTime)*1000), digits = 5))
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
message(paste("HTML : ", print((html_time - startTime)*1000, digits = 5)))
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
print(paste("HTML : ", (html_time - startTime)*1000), digits = 5)
print((html_time - startTime)*1000)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- parser(links, limit = 1)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- parser(links, limit = 1)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- parser(links, limit = 1)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/extractor.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/extractor.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
View(parser(read_html("https://wwW.finextra.com/")))
parser(read_html("https://wwW.finextra.com/"))
parser("https://wwW.finextra.com/")
selector <-  ".left.fullWidth:not(.left.fullWidth.upper.fontColorOne),
#ctl00_ctl00_ConMainBody_ConMainBody_ctl01_pnlBody,
.strong.fullWidth,
.ncMetaDataSnippet,
#ctl00_ctl00_ConMainBody_ConMainBody_ctl01_lblInfo,
#twitterResult,
#liResult,
#fbResult,
#reResult,
#goResult,
#emResult"
months <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")
parser("https://wwW.finextra.com/")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
parser("https://wwW.finextra.com/")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
parser("https://wwW.finextra.com/")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
selector
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
parser("https://wwW.finextra.com/")
View(data)
parser("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router")
debugSource('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
parser("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
parser("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router")
test <- parser("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router")
head(test)
test
View(test)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
View(test)
test <- parser("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router")
View(test)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
test <- parser("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router")
View(test)
View(test)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
test <- parser("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router")
View(test)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- data.frame(test$data)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/Final/WebCrawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- crawler("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", "/newsarticle")
parser <- function(url) {
startTime <- as.numeric(Sys.time())
print(url)
html <- read_html(url)
closeAllConnections()
nodes <- html_nodes(html, "a")
pageLinks <- html_attr(nodes, 'href')
html_time <- as.numeric(Sys.time())
print("HTML")
print((html_time - startTime)*1000)
data <- html_text(html_nodes(html, selector))
data_time <- as.numeric(Sys.time())
print("Data")
print((data_time - html_time)*1000)
#Social networks
social <- sum(as.numeric(data[1:6]))
social_time <- as.numeric(Sys.time())
print("Social")
print((social_time - data_time)*1000)
#Title
title <- data[7]
title_time <- as.numeric(Sys.time())
print("Title")
print((title_time - social_time)*1000)
#Text
text <- paste(data[9], data[10])
text_time <- as.numeric(Sys.time())
print("Text")
print((text_time - title_time)*1000)
#Tags
if (length(data) > 10) {
postTags <- paste(data[11:length(data)], collapse = ",")
}
#Stats
stats <- unlist(strsplit(data[8], "[[:space:]]"))
#Views
views <- as.integer(stats[7])
#Comments
comments <- as.integer(stats[12])
#Time
if (stats[2] == "hours" || stats[2] == "hour") {
hours <- as.integer(stats[1])
time <- startTime - hours * 3600
} else if (stats[2] == "minutes" || stats[2] == "minute") {
minutes <- as.integer(stats[1])
time <- startTime - minutes * 60
} else {
year <- as.integer(stats[3])
month <- which(months == stats[2])
day <- as.integer(stats[1])
date <- ISOdate(year, month, day)
time <- as.integer(date)
}
list(links = pageLinks, data = list(title = title, text = text, social = social, views = views, comments = comments, time = time))
}
df <- crawler("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- crawler("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler("https://www.finextra.com/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", "/newsarticle")
df <- crawler(domain = "https://www.finextra.com", start = "/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler(domain = "https://www.finextra.com", start = "/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
domain = "https://www.finextra.com" + start = "/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router" + path = "/newsarticle"
domain = "https://www.finextra.com"
start = "/newsarticle/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router"
path = "/newsarticle"
start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router"
paste(c(domain, path, start))
paste(c(domain, path, start), sep = "")
paste(domain, path, start, sep = "")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
link <- paste(domain, path, start, sep = "")
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
View(df)
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/extractor.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
#' Parser Function
#'
#' This function gathers data out of the given pages.
#' @param links A list of links to the pages.
#' @param limit The number of pages you want to parse. 0 means all. Defaults to 0.
#' @param beep Will make a sound when finished if set to TRUE. Defaults to FALSE.
#' @export
#' @examples
#' df <- parser(links, 100, T)
library(rvest)
library(tm)
library(beepr)
library(progress)
parser <- function(links, limit = 0, step = 1, beep = T) {
selector <-  ".left.fullWidth:not(.left.fullWidth.upper.fontColorOne),
#ctl00_ctl00_ConMainBody_ConMainBody_ctl01_pnlBody,
.strong.fullWidth,
.ncMetaDataSnippet,
#ctl00_ctl00_ConMainBody_ConMainBody_ctl01_lblInfo,
#twitterResult,
#liResult,
#fbResult,
#reResult,
#goResult,
#emResult"
months <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")
startTime <- as.integer(Sys.time())
df <- data.frame(url = unlist(links))
df$social = NA
df$title  = NA
df$postTags = NA
df$time = NA
df$text = NA
if (limit == 0) {
l <- length(links)
} else {
l <- limit
}
pb <- progress_bar$new(total = l, format = ":spin [:bar] :percent(:i/:total : :tick_rate) : :elapsed/:eta")
for(i in seq.int(l)) {
link <- links[[i]]
html <- read_html(link)
data <- html_text(html_nodes(html, selector))
#Social networks
df$social[i] <- sum(as.numeric(data[1:6]))
#Title
df$title[i] <- data[7]
title_time <- as.numeric(Sys.time())
#Text
df$text[i] <- paste(data[9], data[10])
text_time <- as.numeric(Sys.time())
#Tags
if (length(data) > 10) {
df$postTags[i] <- paste(data[11:length(data)], collapse = ",")
}
#Stats
stats <- unlist(strsplit(data[8], "[[:space:]]"))
#Views
df$views[i] <- as.integer(stats[7])
#Comments
df$comments[i] <- as.integer(stats[12])
#Time
if (stats[2] == "hours" || stats[2] == "hour") {
hours <- as.integer(stats[1])
df$time[i] <- startTime - hours * 3600
} else if (stats[2] == "minutes" || stats[2] == "minute") {
minutes <- as.integer(stats[1])
df$time[i] <- startTime - minutes * 60
} else {
year <- as.integer(stats[3])
month <- which(months == stats[2])
day <- as.integer(stats[1])
date <- ISOdate(year, month, day)
df$time[i] <- as.integer(date)
}
pb$tick(tokens = list(i = as.character(i)))
}
df <- subset(df, !is.na(title))
df$id <- seq.int(length(df$url))
if (beep) {
beep()
}
df[1:length(df$title),]
}
parser <- function(url) {
startTime <- as.numeric(Sys.time())
html <- read_html(url)
closeAllConnections()
nodes <- html_nodes(html, "a")
pageLinks <- html_attr(nodes, 'href')
html_time <- as.numeric(Sys.time())
print("HTML")
print((html_time - startTime)*1000)
data <- html_text(html_nodes(html, selector))
data_time <- as.numeric(Sys.time())
print("Data")
print((data_time - html_time)*1000)
#Social networks
social <- sum(as.numeric(data[1:6]))
social_time <- as.numeric(Sys.time())
print("Social")
print((social_time - data_time)*1000)
#Title
title <- data[7]
title_time <- as.numeric(Sys.time())
print("Title")
print((title_time - social_time)*1000)
#Text
text <- paste(data[9], data[10])
text_time <- as.numeric(Sys.time())
print("Text")
print((text_time - title_time)*1000)
#Tags
if (length(data) > 10) {
postTags <- paste(data[11:length(data)], collapse = ",")
}
#Stats
stats <- unlist(strsplit(data[8], "[[:space:]]"))
#Views
views <- as.integer(stats[7])
#Comments
comments <- as.integer(stats[12])
#Time
if (stats[2] == "hours" || stats[2] == "hour") {
hours <- as.integer(stats[1])
time <- startTime - hours * 3600
} else if (stats[2] == "minutes" || stats[2] == "minute") {
minutes <- as.integer(stats[1])
time <- startTime - minutes * 60
} else {
year <- as.integer(stats[3])
month <- which(months == stats[2])
day <- as.integer(stats[1])
date <- ISOdate(year, month, day)
time <- as.integer(date)
}
list(links = pageLinks, data = list(title = title, text = text, social = social, views = views, comments = comments, time = time))
}
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/parser.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
selector <-  ".left.fullWidth:not(.left.fullWidth.upper.fontColorOne),
#ctl00_ctl00_ConMainBody_ConMainBody_ctl01_pnlBody,
.strong.fullWidth,
.ncMetaDataSnippet,
#ctl00_ctl00_ConMainBody_ConMainBody_ctl01_lblInfo,
#twitterResult,
#liResult,
#fbResult,
#reResult,
#goResult,
#emResult"
months <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
View(df)
debugSource('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
link
parsed
View(pageLinks)
View(df)
View(df)
View(parsed)
data
View(df)
data$text
data$title
data
df[1 = data]
View(df)
df[1,] = data
data$title = as.character(data$title)
df[1,] = data
View(df)
debugSource('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
debugSource('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
View(df)
View(df)
data=
data
test = data.frame(data)
rbind(df , test)
View(df)
test = rbind(df, test)
View(test)
debugSource('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
View(df)
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
source('C:/Users/robin/Desktop/workspace/GitHub/Skaizen/skaizen-package/crawler.R')
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle")
View(df)
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle", n = 3000)
df <- crawler(domain = "https://www.finextra.com", start = "/32414/russian-bank-loses-1-million-to-hackers-who-compromised-an-outdated-router", path = "/newsarticle", n = 2048)
